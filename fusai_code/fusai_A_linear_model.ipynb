{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import csv\n",
    "import matplotlib.dates\n",
    "from datetime import *\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn import ensemble\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "def trainTestSplit(df, splitN, trainLabel):\n",
    "    trainX = df[:splitN][trainLabel]\n",
    "    trainY = df[:splitN]['cnt']\n",
    "    testX = df[splitN:][trainLabel]\n",
    "    testY = df[splitN:]['cnt']\n",
    "    return (trainX, trainY, testX, testY)\n",
    "\n",
    "# 训练模型\n",
    "def trainModel(X, y):\n",
    "#     clf = LinearRegression()\n",
    "#     clf = linear_model.LogisticRegression()\n",
    "#     clf = ensemble.RandomForestRegressor(n_estimators=200)\n",
    "    clf = linear_model.RidgeCV(alphas=[0.01*x for x in range(1,200)], scoring='neg_mean_squared_error')\n",
    "    clf.fit(X, y)\n",
    "    print('Coefficients:', clf.coef_)\n",
    "    return clf\n",
    "\n",
    "# 检验模型\n",
    "def validModel(trainX, trainY, testX, testY):\n",
    "    clf = trainModel(trainX, trainY)\n",
    "    predictY = clf.predict(testX)\n",
    "    cost = np.linalg.norm(predictY - testY)**2 / len(predictY)\n",
    "    print(\"cost:\", cost)\n",
    "    \n",
    "# 添加过去第i周的统计量\n",
    "def statWeek(df, weeks):\n",
    "    if isinstance(weeks, int):\n",
    "        weeks = [weeks]\n",
    "    colName = []\n",
    "    for i in weeks:\n",
    "        weekDf = pd.pivot_table(df, index=['week'], values=['cnt'], aggfunc=[np.mean, np.std, np.max, np.min])\n",
    "        weekDf.columns = ['mean%d'%i, 'std%d'%i, 'max%d'%i, 'min%d'%i]\n",
    "        colName.extend(weekDf.columns)\n",
    "        weekDf.index += i\n",
    "        df = pd.merge(df, weekDf, left_on='week', right_index=True, how='left')\n",
    "    return df,colName\n",
    "\n",
    "# 导出预测结果\n",
    "def exportResult(df, fileName):\n",
    "    df.to_csv('./%s.txt' % fileName, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date  brand  cnt  day_of_week  week  guess_date  date_year  date_month  \\\n",
      "0     1      1   31            2     0  2013-01-01       2013           1   \n",
      "1     1      6    6            2     0  2013-01-01       2013           1   \n",
      "2     1      9   15            2     0  2013-01-01       2013           1   \n",
      "3     2      9    0            3     0  2013-01-02       2013           1   \n",
      "4     2      8    0            3     0  2013-01-02       2013           1   \n",
      "5     2      3    0            3     0  2013-01-02       2013           1   \n",
      "6     2      2    0            3     0  2013-01-02       2013           1   \n",
      "7     2      7   30            3     0  2013-01-02       2013           1   \n",
      "8     2      6    6            3     0  2013-01-02       2013           1   \n",
      "9     2      4   20            3     0  2013-01-02       2013           1   \n",
      "\n",
      "   date_property guess_date_str    ...     brand_1 brand_2  brand_3  brand_4  \\\n",
      "0              2     2013-01-01    ...           1       0        0        0   \n",
      "1              2     2013-01-01    ...           0       0        0        0   \n",
      "2              2     2013-01-01    ...           0       0        0        0   \n",
      "3              2     2013-01-02    ...           0       0        0        0   \n",
      "4              2     2013-01-02    ...           0       0        0        0   \n",
      "5              2     2013-01-02    ...           0       0        1        0   \n",
      "6              2     2013-01-02    ...           0       1        0        0   \n",
      "7              2     2013-01-02    ...           0       0        0        0   \n",
      "8              2     2013-01-02    ...           0       0        0        0   \n",
      "9              2     2013-01-02    ...           0       0        0        1   \n",
      "\n",
      "   brand_5  brand_6  brand_7  brand_8  brand_9  brand_10  \n",
      "0        0        0        0        0        0         0  \n",
      "1        0        1        0        0        0         0  \n",
      "2        0        0        0        0        1         0  \n",
      "3        0        0        0        0        1         0  \n",
      "4        0        0        0        1        0         0  \n",
      "5        0        0        0        0        0         0  \n",
      "6        0        0        0        0        0         0  \n",
      "7        0        0        1        0        0         0  \n",
      "8        0        1        0        0        0         0  \n",
      "9        0        0        0        0        0         0  \n",
      "\n",
      "[10 rows x 59 columns]\n"
     ]
    }
   ],
   "source": [
    "#导入训练数据\n",
    "train_data = pd.read_csv('fusai_A_train_feature_set.csv')\n",
    "\n",
    "print(train_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7806 entries, 0 to 7805\n",
      "Data columns (total 41 columns):\n",
      "sale_quantity_scaled    7806 non-null float64\n",
      "day_of_week_1           7806 non-null int64\n",
      "day_of_week_2           7806 non-null int64\n",
      "day_of_week_3           7806 non-null int64\n",
      "day_of_week_4           7806 non-null int64\n",
      "day_of_week_5           7806 non-null int64\n",
      "day_of_week_6           7806 non-null int64\n",
      "day_of_week_7           7806 non-null int64\n",
      "date_property_0         7806 non-null int64\n",
      "date_property_1         7806 non-null int64\n",
      "date_property_2         7806 non-null int64\n",
      "date_month_1            7806 non-null int64\n",
      "date_month_2            7806 non-null int64\n",
      "date_month_3            7806 non-null int64\n",
      "date_month_4            7806 non-null int64\n",
      "date_month_5            7806 non-null int64\n",
      "date_month_6            7806 non-null int64\n",
      "date_month_7            7806 non-null int64\n",
      "date_month_8            7806 non-null int64\n",
      "date_month_9            7806 non-null int64\n",
      "date_month_10           7806 non-null int64\n",
      "date_month_11           7806 non-null int64\n",
      "date_month_12           7806 non-null int64\n",
      "after_restday_one       7806 non-null int64\n",
      "after_holiday_one       7806 non-null int64\n",
      "is_holi_restday         7806 non-null int64\n",
      "is_newYearDay           7806 non-null int64\n",
      "isHolidayWeekend        7806 non-null int64\n",
      "isPureWeekend           7806 non-null int64\n",
      "is_NationalDay          7806 non-null int64\n",
      "is_ChineseNewYearDay    7806 non-null int64\n",
      "brand_1                 7806 non-null int64\n",
      "brand_2                 7806 non-null int64\n",
      "brand_3                 7806 non-null int64\n",
      "brand_4                 7806 non-null int64\n",
      "brand_5                 7806 non-null int64\n",
      "brand_6                 7806 non-null int64\n",
      "brand_7                 7806 non-null int64\n",
      "brand_8                 7806 non-null int64\n",
      "brand_9                 7806 non-null int64\n",
      "brand_10                7806 non-null int64\n",
      "dtypes: float64(1), int64(40)\n",
      "memory usage: 2.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 划分训练测试集\n",
    "splitN = int(train_data.index[-1] * 0.67)\n",
    "fea = ['sale_quantity_scaled', 'day_of_week_1', 'day_of_week_2', 'day_of_week_3',\n",
    "      'day_of_week_4', 'day_of_week_5', 'day_of_week_6', 'day_of_week_7', 'date_property_0', 'date_property_1', 'date_property_2',\n",
    "       'date_month_1', 'date_month_2', 'date_month_3', 'date_month_4', 'date_month_5', 'date_month_6', 'date_month_7',\n",
    "       'date_month_8', 'date_month_9', 'date_month_10', 'date_month_11', 'date_month_12',\n",
    "      'after_restday_one', 'after_holiday_one', 'is_holi_restday', 'is_newYearDay', 'isHolidayWeekend', 'isPureWeekend',\n",
    "       'is_NationalDay', 'is_ChineseNewYearDay']\n",
    "# fea = [ 'sale_quantity_scaled', 'day_of_week_1', 'day_of_week_2', 'day_of_week_3',\n",
    "#       'day_of_week_4', 'day_of_week_5', 'day_of_week_6', 'day_of_week_7', 'date_property_0', 'date_property_1', 'date_property_2',\n",
    "#       'date_month_1', 'date_month_2', 'date_month_3', 'date_month_4', 'date_month_5', 'date_month_6', 'date_month_7',\n",
    "#       'date_month_8', 'date_month_9', 'date_month_10', 'date_month_11', 'date_month_12',\n",
    "#        'dividedMonth_late', 'dividedMonth_early',\n",
    "#       'after_restday_one', 'after_holiday_one', 'is_holi_restday', 'is_newYearDay', 'isHolidayWeekend', 'isPureWeekend',\n",
    "#         'brand_1', 'brand_2', 'brand_3', 'brand_4', 'brand_5',\n",
    "#        'brand_6', 'brand_7', 'brand_8', 'brand_9', 'brand_10']\n",
    "trainX,trainY,testX,testY = trainTestSplit(train_data, splitN, fea)\n",
    "print(trainX.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: 39218.8291952\n"
     ]
    }
   ],
   "source": [
    "#检验模型\n",
    "validModel(trainX.values, trainY.values, testX.values, testY.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 正式模型\n",
    "modelName = \"linear2\"\n",
    "clf = trainModel(train_data[:][fea].values, train_data[:]['cnt'].values)\n",
    "# clf = trainModel(train_data[-750:][fea].values, train_data[-750:]['cnt'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date  day_of_week  brand  week  guess_date  date_year  date_month  \\\n",
      "0  1107            4      7   174  2016-05-05       2016           5   \n",
      "1  1107            4      8   174  2016-05-05       2016           5   \n",
      "2  1107            4      9   174  2016-05-05       2016           5   \n",
      "3  1107            4     10   174  2016-05-05       2016           5   \n",
      "4  1108            5      1   174  2016-05-06       2016           5   \n",
      "5  1108            5      2   174  2016-05-06       2016           5   \n",
      "6  1108            5      3   174  2016-05-06       2016           5   \n",
      "7  1108            5      4   174  2016-05-06       2016           5   \n",
      "8  1108            5      5   174  2016-05-06       2016           5   \n",
      "9  1108            5      6   174  2016-05-06       2016           5   \n",
      "\n",
      "   date_property guess_date_str  sale_quantity      ...       brand_7  \\\n",
      "0              0     2016-05-05        42158.0      ...             1   \n",
      "1              0     2016-05-05        42158.0      ...             0   \n",
      "2              0     2016-05-05        42158.0      ...             0   \n",
      "3              0     2016-05-05        42158.0      ...             0   \n",
      "4              0     2016-05-06        42158.0      ...             0   \n",
      "5              0     2016-05-06        42158.0      ...             0   \n",
      "6              0     2016-05-06        42158.0      ...             0   \n",
      "7              0     2016-05-06        42158.0      ...             0   \n",
      "8              0     2016-05-06        42158.0      ...             0   \n",
      "9              0     2016-05-06        42158.0      ...             0   \n",
      "\n",
      "   brand_8  brand_9  brand_10  date_month_1  date_month_2  date_month_3  \\\n",
      "0        0        0         0             0             0             0   \n",
      "1        1        0         0             0             0             0   \n",
      "2        0        1         0             0             0             0   \n",
      "3        0        0         1             0             0             0   \n",
      "4        0        0         0             0             0             0   \n",
      "5        0        0         0             0             0             0   \n",
      "6        0        0         0             0             0             0   \n",
      "7        0        0         0             0             0             0   \n",
      "8        0        0         0             0             0             0   \n",
      "9        0        0         0             0             0             0   \n",
      "\n",
      "   date_month_4  date_month_11  date_month_12  \n",
      "0             0              0              0  \n",
      "1             0              0              0  \n",
      "2             0              0              0  \n",
      "3             0              0              0  \n",
      "4             0              0              0  \n",
      "5             0              0              0  \n",
      "6             0              0              0  \n",
      "7             0              0              0  \n",
      "8             0              0              0  \n",
      "9             0              0              0  \n",
      "\n",
      "[10 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "#导入测试数据\n",
    "test_data = pd.read_csv('fusai_A_test_feature_set.csv')\n",
    "\n",
    "print(test_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    date  day_of_week  brand     predict\n",
      "0   1107            4      7  252.351019\n",
      "1   1107            4      8  433.951217\n",
      "2   1107            4      9  602.834515\n",
      "3   1107            4     10  296.612647\n",
      "4   1108            5      1  314.063756\n",
      "5   1108            5      2  224.604121\n",
      "6   1108            5      3  312.538544\n",
      "7   1108            5      4  547.354317\n",
      "8   1108            5      5  384.672361\n",
      "9   1108            5      6  348.312556\n",
      "10  1108            5      7  364.559470\n",
      "11  1108            5      8  611.713323\n",
      "12  1108            5      9  778.462694\n",
      "13  1108            5     10  348.317426\n",
      "14  1109            6      1   54.013714\n",
      "15  1109            6      2   73.298083\n",
      "16  1109            6      3   69.780825\n",
      "17  1109            6      4  104.838165\n",
      "18  1109            6      5   83.226859\n",
      "19  1109            6      6   56.282413\n",
      "20  1109            6      7   70.103665\n",
      "21  1109            6      8   91.318944\n",
      "22  1109            6      9  213.648895\n",
      "23  1109            6     10   47.464139\n",
      "24  1110            7      9    3.685567\n",
      "25  1111            1      1  400.476075\n",
      "26  1111            1      2  236.839862\n",
      "27  1111            1      3  391.574762\n",
      "28  1111            1      4  676.751123\n",
      "29  1111            1      5  478.271329\n",
      "..   ...          ...    ...         ...\n",
      "70  1115            5      6  348.312556\n",
      "71  1115            5      7  364.559470\n",
      "72  1115            5      8  611.713323\n",
      "73  1115            5      9  778.462694\n",
      "74  1115            5     10  348.317426\n",
      "75  1116            6      1   54.013714\n",
      "76  1116            6      2   73.298083\n",
      "77  1116            6      3   69.780825\n",
      "78  1116            6      4  104.838165\n",
      "79  1116            6      5   83.226859\n",
      "80  1116            6      6   56.282413\n",
      "81  1116            6      7   70.103665\n",
      "82  1116            6      8   91.318944\n",
      "83  1116            6      9  213.648895\n",
      "84  1116            6     10   47.464139\n",
      "85  1117            1      1  400.476075\n",
      "86  1117            1      2  236.839862\n",
      "87  1117            1      3  391.574762\n",
      "88  1117            1      4  676.751123\n",
      "89  1117            1      5  478.271329\n",
      "90  1117            1      6  356.344665\n",
      "91  1117            1      7  423.031505\n",
      "92  1117            1      8  675.712591\n",
      "93  1117            1      9  876.545141\n",
      "94  1117            1     10  460.328103\n",
      "95  1118            2      1  384.394275\n",
      "96  1118            2      2  304.320054\n",
      "97  1118            2      3  407.433421\n",
      "98  1118            2      4  638.401948\n",
      "99  1118            2      5  466.313321\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#进行预测\n",
    "predict = clf.predict(test_data[:][fea].values)\n",
    "\n",
    "predict_df = pd.read_csv('fusai_test_A_20180227.txt', sep='\\t')\n",
    "predict_df['predict'] = predict\n",
    "predict_df['predict'] = predict_df.predict.map(lambda x: 10 if x < 0 else x)\n",
    "\n",
    "print(predict_df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#保存预测结果\n",
    "exportResult(predict_df[['date','brand', 'predict']], 'random_forest_A_fullfilling_fusai_3_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
