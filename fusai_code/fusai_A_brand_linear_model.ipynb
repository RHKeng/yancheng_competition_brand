{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import csv\n",
    "import matplotlib.dates\n",
    "from datetime import *\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn import ensemble\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "def trainTestSplit(df, splitN, trainLabel):\n",
    "    trainX = df[:splitN][trainLabel]\n",
    "    trainY = df[:splitN]['cnt']\n",
    "    testX = df[splitN:][trainLabel]\n",
    "    testY = df[splitN:]['cnt']\n",
    "    return (trainX, trainY, testX, testY)\n",
    "\n",
    "# 训练模型\n",
    "def trainLinearModel(X, y):\n",
    "    clf = linear_model.RidgeCV(alphas=[0.01*x for x in range(1,200)], scoring='neg_mean_squared_error')\n",
    "    clf.fit(X, y)\n",
    "    print('Coefficients:', clf.coef_)\n",
    "    return clf\n",
    "\n",
    "# 训练模型\n",
    "def trainTreeModel(X, y):\n",
    "#     clf = ensemble.RandomForestRegressor(n_estimators=200)\n",
    "    clf = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=0, loss='ls')\n",
    "    clf.fit(X, y)\n",
    "    return clf\n",
    "\n",
    "# 检验模型\n",
    "def validModel(trainX, trainY, testX, testY):\n",
    "    clf = trainLinearModel(trainX, trainY)\n",
    "    predictY = clf.predict(testX)\n",
    "    cost = np.linalg.norm(predictY - testY)**2 / len(predictY)\n",
    "    print(\"cost:\", cost)\n",
    "    \n",
    "# 添加过去第i周的统计量\n",
    "def statWeek(df, weeks):\n",
    "    if isinstance(weeks, int):\n",
    "        weeks = [weeks]\n",
    "    colName = []\n",
    "    for i in weeks:\n",
    "        weekDf = pd.pivot_table(df, index=['week'], values=['cnt'], aggfunc=[np.mean, np.std, np.max, np.min])\n",
    "        weekDf.columns = ['mean%d'%i, 'std%d'%i, 'max%d'%i, 'min%d'%i]\n",
    "        colName.extend(weekDf.columns)\n",
    "        weekDf.index += i\n",
    "        df = pd.merge(df, weekDf, left_on='week', right_index=True, how='left')\n",
    "    return df,colName\n",
    "\n",
    "# 导出预测结果\n",
    "def exportResult(df, fileName):\n",
    "    df.to_csv('./%s.txt' % fileName, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date  day_of_week  brand  cnt  guess_date  date_year  date_month_day  \\\n",
      "0     1            2      1   31  2013-01-01       2013               1   \n",
      "1     1            2      6    6  2013-01-01       2013               1   \n",
      "2     1            2      9   15  2013-01-01       2013               1   \n",
      "3     2            3      4   20  2013-01-02       2013               2   \n",
      "4     2            3      6    6  2013-01-02       2013               2   \n",
      "5     2            3      7   30  2013-01-02       2013               2   \n",
      "6     2            3     10   48  2013-01-02       2013               2   \n",
      "7     3            4      4   16  2013-01-03       2013               3   \n",
      "8     3            4      6    4  2013-01-03       2013               3   \n",
      "9     3            4      8   23  2013-01-03       2013               3   \n",
      "\n",
      "   date_property guess_date_str  sale_quantity    ...     brand_1 brand_2  \\\n",
      "0              2     2013-01-01        28137.0    ...           1       0   \n",
      "1              2     2013-01-01        28137.0    ...           0       0   \n",
      "2              2     2013-01-01        28137.0    ...           0       0   \n",
      "3              2     2013-01-02        28137.0    ...           0       0   \n",
      "4              2     2013-01-02        28137.0    ...           0       0   \n",
      "5              2     2013-01-02        28137.0    ...           0       0   \n",
      "6              2     2013-01-02        28137.0    ...           0       0   \n",
      "7              2     2013-01-03        28137.0    ...           0       0   \n",
      "8              2     2013-01-03        28137.0    ...           0       0   \n",
      "9              2     2013-01-03        28137.0    ...           0       0   \n",
      "\n",
      "   brand_3  brand_4  brand_5  brand_6  brand_7  brand_8  brand_9  brand_10  \n",
      "0        0        0        0        0        0        0        0         0  \n",
      "1        0        0        0        1        0        0        0         0  \n",
      "2        0        0        0        0        0        0        1         0  \n",
      "3        0        1        0        0        0        0        0         0  \n",
      "4        0        0        0        1        0        0        0         0  \n",
      "5        0        0        0        0        1        0        0         0  \n",
      "6        0        0        0        0        0        0        0         1  \n",
      "7        0        1        0        0        0        0        0         0  \n",
      "8        0        0        0        1        0        0        0         0  \n",
      "9        0        0        0        0        0        1        0         0  \n",
      "\n",
      "[10 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "#导入训练数据\n",
    "train_data = pd.read_csv('fusai_A_train_feature_set.csv')\n",
    "\n",
    "print(train_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 696 entries, 11 to 6509\n",
      "Data columns (total 32 columns):\n",
      "date_month_day_scaled    696 non-null float64\n",
      "sale_quantity_scaled     696 non-null float64\n",
      "day_of_week_1            696 non-null int64\n",
      "day_of_week_2            696 non-null int64\n",
      "day_of_week_3            696 non-null int64\n",
      "day_of_week_4            696 non-null int64\n",
      "day_of_week_5            696 non-null int64\n",
      "day_of_week_6            696 non-null int64\n",
      "day_of_week_7            696 non-null int64\n",
      "date_property_0          696 non-null int64\n",
      "date_property_1          696 non-null int64\n",
      "date_property_2          696 non-null int64\n",
      "date_month_1             696 non-null int64\n",
      "date_month_2             696 non-null int64\n",
      "date_month_3             696 non-null int64\n",
      "date_month_4             696 non-null int64\n",
      "date_month_5             696 non-null int64\n",
      "date_month_6             696 non-null int64\n",
      "date_month_7             696 non-null int64\n",
      "date_month_8             696 non-null int64\n",
      "date_month_9             696 non-null int64\n",
      "date_month_10            696 non-null int64\n",
      "date_month_11            696 non-null int64\n",
      "date_month_12            696 non-null int64\n",
      "after_restday_one        696 non-null int64\n",
      "after_holiday_one        696 non-null int64\n",
      "is_holi_restday          696 non-null int64\n",
      "is_newYearDay            696 non-null int64\n",
      "isHolidayWeekend         696 non-null int64\n",
      "isPureWeekend            696 non-null int64\n",
      "is_NationalDay           696 non-null int64\n",
      "is_ChineseNewYearDay     696 non-null int64\n",
      "dtypes: float64(2), int64(30)\n",
      "memory usage: 179.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 划分训练测试集\n",
    "splitN = int(len(train_data[train_data.brand == 9]) * 0.67)\n",
    "fea = ['date_month_day_scaled', 'sale_quantity_scaled', 'day_of_week_1', 'day_of_week_2', 'day_of_week_3',\n",
    "      'day_of_week_4', 'day_of_week_5', 'day_of_week_6', 'day_of_week_7', 'date_property_0', 'date_property_1', 'date_property_2',\n",
    "       'date_month_1', 'date_month_2', 'date_month_3', 'date_month_4', 'date_month_5', 'date_month_6', 'date_month_7',\n",
    "       'date_month_8', 'date_month_9', 'date_month_10', 'date_month_11', 'date_month_12',\n",
    "      'after_restday_one', 'after_holiday_one', 'is_holi_restday', 'is_newYearDay', 'isHolidayWeekend', 'isPureWeekend',\n",
    "       'is_NationalDay', 'is_ChineseNewYearDay']\n",
    "# fea = ['date_month_day_scaled', 'week_scaled', 'date_year_scaled', 'sale_quantity_scaled', 'day_of_week_1', 'day_of_week_2', 'day_of_week_3',\n",
    "#       'day_of_week_4', 'day_of_week_5', 'day_of_week_6', 'day_of_week_7', 'date_property_0', 'date_property_1', 'date_property_2',\n",
    "#       'date_month_1', 'date_month_2', 'date_month_3', 'date_month_4', 'date_month_5', 'date_month_6', 'date_month_7',\n",
    "#       'date_month_8', 'date_month_9', 'date_month_10', 'date_month_11', 'date_month_12',\n",
    "#        'dividedMonth_late', 'dividedMonth_early',\n",
    "#       'after_restday_one', 'after_holiday_one', 'is_holi_restday', 'is_newYearDay', 'isHolidayWeekend', 'isPureWeekend',\n",
    "#         'brand_1', 'brand_2', 'brand_3', 'brand_4', 'brand_5',\n",
    "#        'brand_6', 'brand_7', 'brand_8', 'brand_9', 'brand_10']\n",
    "trainX,trainY,testX,testY = trainTestSplit(train_data[train_data.brand == 2], splitN, fea)\n",
    "print(trainX.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ -12.3407972    56.93897138   28.87091046   28.39394979    3.85772303\n",
      "  -65.65274556  -24.79443159   19.7791096     9.54548426  110.24463421\n",
      "  -50.66164191  -59.5829923   127.33779584   31.51766942  -39.20051054\n",
      "  -34.56342029    4.02236671  -65.97324836  -37.54099481  -21.0498203\n",
      "   10.3498782    10.51467016  -27.29266751   41.8782815   -19.81342081\n",
      "  164.58585155  -27.98901826    0.          -31.59397403  -50.66164191\n",
      "  -19.76786649   -4.56855367]\n",
      "cost: 17535.7257162\n"
     ]
    }
   ],
   "source": [
    "#检验模型\n",
    "validModel(trainX.values, trainY.values, testX.values, testY.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date  day_of_week  brand  week  guess_date  date_year  date_month  \\\n",
      "0  1107            4      7   174  2016-05-05       2016           5   \n",
      "1  1107            4      8   174  2016-05-05       2016           5   \n",
      "2  1107            4      9   174  2016-05-05       2016           5   \n",
      "3  1107            4     10   174  2016-05-05       2016           5   \n",
      "4  1108            5      1   174  2016-05-06       2016           5   \n",
      "5  1108            5      2   174  2016-05-06       2016           5   \n",
      "6  1108            5      3   174  2016-05-06       2016           5   \n",
      "7  1108            5      4   174  2016-05-06       2016           5   \n",
      "8  1108            5      5   174  2016-05-06       2016           5   \n",
      "9  1108            5      6   174  2016-05-06       2016           5   \n",
      "\n",
      "   date_month_day  date_property guess_date_str      ...        brand_7  \\\n",
      "0               5              0     2016-05-05      ...              1   \n",
      "1               5              0     2016-05-05      ...              0   \n",
      "2               5              0     2016-05-05      ...              0   \n",
      "3               5              0     2016-05-05      ...              0   \n",
      "4               6              0     2016-05-06      ...              0   \n",
      "5               6              0     2016-05-06      ...              0   \n",
      "6               6              0     2016-05-06      ...              0   \n",
      "7               6              0     2016-05-06      ...              0   \n",
      "8               6              0     2016-05-06      ...              0   \n",
      "9               6              0     2016-05-06      ...              0   \n",
      "\n",
      "  brand_8  brand_9  brand_10  date_month_1  date_month_2  date_month_3  \\\n",
      "0       0        0         0             0             0             0   \n",
      "1       1        0         0             0             0             0   \n",
      "2       0        1         0             0             0             0   \n",
      "3       0        0         1             0             0             0   \n",
      "4       0        0         0             0             0             0   \n",
      "5       0        0         0             0             0             0   \n",
      "6       0        0         0             0             0             0   \n",
      "7       0        0         0             0             0             0   \n",
      "8       0        0         0             0             0             0   \n",
      "9       0        0         0             0             0             0   \n",
      "\n",
      "   date_month_4  date_month_11  date_month_12  \n",
      "0             0              0              0  \n",
      "1             0              0              0  \n",
      "2             0              0              0  \n",
      "3             0              0              0  \n",
      "4             0              0              0  \n",
      "5             0              0              0  \n",
      "6             0              0              0  \n",
      "7             0              0              0  \n",
      "8             0              0              0  \n",
      "9             0              0              0  \n",
      "\n",
      "[10 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "#导入测试数据\n",
    "test_data = pd.read_csv('fusai_A_test_feature_set.csv')\n",
    "\n",
    "print(test_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ -35.39247171   44.47194222   89.64674053   30.71230204   -8.44979185\n",
      "  -73.04808121  -36.09521518   13.51978333  -16.28573766  148.52783254\n",
      "  -69.48955907  -79.03827347  155.9725058   189.57916319   46.33329688\n",
      "  -12.03524075  -29.69039301  -47.86679365  -43.73191118  -75.92893842\n",
      "  -48.3984538   -30.04585299  -42.36922603  -61.81815604  -51.10965873\n",
      "  243.97517035  -34.28184733 -195.80642881  -44.75642614  -69.48955907\n",
      "    0.            0.        ]\n",
      "Coefficients: [ -1.38422787e+01   6.02371223e+01   6.83035897e+01   3.31870624e+01\n",
      "   2.32525648e+00  -7.09986111e+01  -3.11036046e+01   2.16955460e-01\n",
      "  -1.93064842e+00   1.17747027e+02  -4.14567936e+01  -7.62902337e+01\n",
      "   1.65136458e+02   5.34860775e+01  -2.57759880e+01  -3.55845050e+01\n",
      "   2.63127934e+00  -6.56453814e+01  -4.73990614e+01  -3.23452364e+01\n",
      "  -7.43747909e+00   1.18192708e+01  -3.92018657e+01   2.03164317e+01\n",
      "  -6.71081274e+01   2.22715191e+02  -3.86197351e+01  -1.64374329e+02\n",
      "  -3.76704987e+01  -4.14567936e+01  -8.30313666e+00   1.37640249e+00]\n",
      "Coefficients: [   0.46700202  195.26388535   17.86210897   56.35798495   22.01380826\n",
      "  -43.35680535    0.93293448  -23.53778025  -30.27225106   87.92920744\n",
      "  -34.94780305  -52.98140439   78.24393256  -15.16063549  -25.14663803\n",
      "  -12.99769993   -4.82720373  -16.02987576   -9.0586739   -11.35483956\n",
      "   18.73606658    9.03723949  -19.86276451    8.42109228   35.44711763\n",
      "  110.38281524  -31.49937726  -45.17638575  -21.48202712  -34.94780305\n",
      "    0.            0.        ]\n",
      "Coefficients: [-111.49251635  131.25045311  111.82884051  135.89271028   13.53464603\n",
      " -108.08095537  -44.74962988  -44.28782594  -64.13778563  195.53760736\n",
      "  -70.38463584 -125.15297153  233.65557173  189.01502467   50.58756525\n",
      "   -3.93207986  -36.98257505  -83.47098043 -110.11244041  -94.99403645\n",
      "  -64.60180252    7.53641965  -60.57516299  -26.12550359  -43.50481205\n",
      "  318.37547297 -107.98631639 -203.43915609  -17.16665513  -70.38463584\n",
      "  -29.72084294 -189.74673414]\n",
      "Coefficients: [ -58.82897257  467.53724686  135.43131839   81.81632899   31.27650351\n",
      "  -33.63829405    7.30232913 -119.69353165 -102.49465433   55.33407625\n",
      "   -8.64139369  -46.69268256   33.1183908    32.45825951  -13.94938151\n",
      "   71.10533238   35.13410307  -15.77679963   25.36770276   46.68678483\n",
      "  -37.95991498  -53.84243864  -45.25110556  -77.09093304  -24.09149147\n",
      "  315.99833496   -7.19977755    0.          -39.49290502   -8.64139369\n",
      "   -7.19977755    0.        ]\n",
      "Coefficients: [ -16.36469239  192.68059045   23.66204615   43.15751135   16.89763282\n",
      "  -35.88324694    2.074748    -26.080517    -23.82817439   99.87570347\n",
      "  -29.30326819  -70.57243528   59.44686902  -10.27438189  -12.13936186\n",
      "   -9.78802988    8.8095147   -14.5826053    -1.55491568    3.02132053\n",
      "    7.99566733    5.0266811   -14.58581415  -21.37494391  -15.01956596\n",
      "  114.6307827   -49.0419787   -94.78874455  -21.53045658  -29.30326819\n",
      "  -23.85830482  -42.03735064]\n",
      "Coefficients: [ -24.19298293  223.98421243   11.98688053   63.44336994   17.17284643\n",
      "  -35.30592988   -1.27560368  -41.73241745  -14.28914589   92.92724331\n",
      "  -32.30638832  -60.62085499   60.95312493  -43.73787233  -14.73987963\n",
      "   -4.03140069   20.56923923   17.13615307    0.41351278   10.39056258\n",
      "   30.68064194    3.10890025  -25.06222818  -55.68075396  -10.75300567\n",
      "  -14.36752116  -19.92935121 -166.40653163  -40.69150378  -32.30638832\n",
      " -114.7748727    18.81526076]\n",
      "Coefficients: [ -4.20717648e+01   6.52565537e+02   7.34430257e+01   6.02831053e+01\n",
      "   8.49458907e+00  -4.54500868e+01  -2.54086514e+01  -6.56548009e+01\n",
      "  -5.70718110e+00   1.12677297e+02  -2.22251971e+01  -9.04520999e+01\n",
      "  -3.04976668e+01  -6.39637595e+00   7.19475194e+00   4.75610346e+01\n",
      "   4.42983163e+00  -1.70372009e+01   3.05116123e+00   1.74691803e+01\n",
      "   1.29453961e-01  -7.43828098e+00  -1.34685975e+01  -4.99729154e+00\n",
      "  -4.79567793e+01   1.63983087e+02  -9.04520999e+01   1.12559369e+01\n",
      "   0.00000000e+00  -2.22251971e+01  -5.57337584e+01  -4.59742785e+01]\n",
      "Coefficients: [ -37.17620147  -58.06112666   54.93422942   45.24233737    2.38033787\n",
      "  -84.42241045  -15.35004031   -6.84484543    4.06039153  219.97354176\n",
      "  -89.31257787 -130.66096388  252.51150579  107.22263566  -96.44285147\n",
      "  -84.46249745  -12.60075141  -99.48915095  -49.50290558  -30.79039283\n",
      "   27.00613416   38.81412465  -34.04661377  -18.21923679   20.87039031\n",
      "  407.89872221 -100.59695147  -93.00154933  -30.06401241  -89.31257787\n",
      "  -27.61713537  -39.42276802]\n",
      "    date  day_of_week  brand     predict\n",
      "0   1107            4      7  301.778123\n",
      "1   1107            4      8  291.870415\n",
      "2   1107            4      9  618.469733\n",
      "3   1107            4     10  371.415818\n",
      "4   1108            5      1  292.975819\n",
      "5   1108            5      2  254.015967\n",
      "6   1108            5      3  283.227612\n",
      "7   1108            5      4  428.415197\n",
      "8   1108            5      5  305.402690\n",
      "9   1108            5      6  280.851730\n",
      "10  1108            5      7  335.002016\n",
      "11  1108            5      8  310.509458\n",
      "12  1108            5      9  778.993635\n",
      "13  1108            5     10  439.248982\n",
      "14  1109            6      1   53.904118\n",
      "15  1109            6      2   84.214503\n",
      "16  1109            6      3  100.947651\n",
      "17  1109            6      4   88.853705\n",
      "18  1109            6      5  103.829000\n",
      "19  1109            6      6   93.668736\n",
      "20  1109            6      7  136.198750\n",
      "21  1109            6      8  111.733225\n",
      "22  1109            6      9  150.654803\n",
      "23  1109            6     10   47.916272\n",
      "24  1110            7      9   13.981986\n",
      "25  1111            1      1  364.068869\n",
      "26  1111            1      2  284.930806\n",
      "27  1111            1      3  335.650604\n",
      "28  1111            1      4  530.339604\n",
      "29  1111            1      5  403.557291\n",
      "..   ...          ...    ...         ...\n",
      "70  1115            5      6  277.033302\n",
      "71  1115            5      7  329.356987\n",
      "72  1115            5      8  300.692713\n",
      "73  1115            5      9  761.611658\n",
      "74  1115            5     10  430.574535\n",
      "75  1116            6      1   45.645875\n",
      "76  1116            6      2   80.984638\n",
      "77  1116            6      3  101.056618\n",
      "78  1116            6      4   62.838784\n",
      "79  1116            6      5   90.102240\n",
      "80  1116            6      6   89.850308\n",
      "81  1116            6      7  130.553721\n",
      "82  1116            6      8  101.916480\n",
      "83  1116            6      9  150.654803\n",
      "84  1116            6     10   39.241825\n",
      "85  1117            1      1  355.810626\n",
      "86  1117            1      2  281.700941\n",
      "87  1117            1      3  335.759572\n",
      "88  1117            1      4  504.324683\n",
      "89  1117            1      5  389.830531\n",
      "90  1117            1      6  281.964565\n",
      "91  1117            1      7  329.447167\n",
      "92  1117            1      8  347.380434\n",
      "93  1117            1      9  810.021821\n",
      "94  1117            1     10  518.011574\n",
      "95  1118            2      1  346.806097\n",
      "96  1118            2      2  313.231132\n",
      "97  1118            2      3  338.823897\n",
      "98  1118            2      4  568.176948\n",
      "99  1118            2      5  358.346067\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#定义树模型预测函数\n",
    "def predictTreeModelByBrand(df, fea, brand):\n",
    "    clf = trainTreeModel(df[df.brand == brand][fea].values, df[df.brand == brand]['cnt'].values)\n",
    "    #进行预测\n",
    "    test_data_brand = test_data[test_data.brand == brand][['date', 'day_of_week', 'guess_date', 'brand']]\n",
    "    predict = clf.predict(test_data[test_data.brand == brand][fea].values)\n",
    "    test_data_brand['predict'] = predict\n",
    "    return test_data_brand\n",
    "\n",
    "#定义线性模型预测函数\n",
    "def predictLinearModelByBrand(df, fea, brand):\n",
    "    clf = trainLinearModel(df[df.brand == brand][fea].values, df[df.brand == brand]['cnt'].values)\n",
    "    #进行预测\n",
    "    test_data_brand = test_data[test_data.brand == brand][['date', 'day_of_week', 'guess_date', 'brand']]\n",
    "    predict = clf.predict(test_data[test_data.brand == brand][fea].values)\n",
    "    test_data_brand['predict'] = predict\n",
    "    return test_data_brand\n",
    "\n",
    "predict_data = predictTreeModelByBrand(train_data, fea, 9)\n",
    "predict_data = pd.concat([predict_data, predictLinearModelByBrand(train_data, fea, 1)])\n",
    "predict_data = pd.concat([predict_data, predictLinearModelByBrand(train_data, fea, 2)])\n",
    "predict_data = pd.concat([predict_data, predictLinearModelByBrand(train_data, fea, 3)])\n",
    "predict_data = pd.concat([predict_data, predictLinearModelByBrand(train_data, fea, 4)])\n",
    "predict_data = pd.concat([predict_data, predictLinearModelByBrand(train_data, fea, 5)])\n",
    "predict_data = pd.concat([predict_data, predictLinearModelByBrand(train_data, fea, 6)])\n",
    "predict_data = pd.concat([predict_data, predictLinearModelByBrand(train_data, fea, 7)])\n",
    "predict_data = pd.concat([predict_data, predictLinearModelByBrand(train_data, fea, 8)])\n",
    "predict_data = pd.concat([predict_data, predictLinearModelByBrand(train_data, fea, 10)])\n",
    "\n",
    "predict_df = pd.read_csv('fusai_test_A_20180227.txt', sep='\\t')\n",
    "predict_df['predict'] = -1\n",
    "for i in range(len(predict_df)):\n",
    "    date = predict_df.iloc[[i], [0]].values[0][0]\n",
    "    brand = predict_df.iloc[[i], [2]].values[0][0]\n",
    "    predict_df.predict[(predict_df.date == date) & (predict_df.brand == brand)] = predict_data.predict[(predict_data.date == date) & (predict_data.brand == brand)]\n",
    "predict_df['predict'] = predict_df.predict.map(lambda x: 10 if x < 10 else x)\n",
    "print(predict_df.head(100))\n",
    "\n",
    "# print(predict_df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#保存预测结果\n",
    "exportResult(predict_df[['date','brand', 'predict']], 'brand_A_fusai_3_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
